package services

import (
	"fmt"
	"time"

	"github.com/codelieche/cronjob/apiserver/pkg/store"
	"github.com/codelieche/cronjob/apiserver/pkg/utils/logger"
	"go.uber.org/zap"
)

// StatsAggregator ç»Ÿè®¡æ•°æ®èšåˆå™¨ï¼ˆService å±‚ï¼‰
//
// è´Ÿè´£ç»Ÿè®¡æ•°æ®èšåˆçš„ä¸šåŠ¡é€»è¾‘
// é€šè¿‡åå°å®šæ—¶ä»»åŠ¡æ¯æ—¥å‡Œæ™¨è‡ªåŠ¨æ‰§è¡Œï¼Œå¤§å¹…æå‡ç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½
//
// ğŸ”¥ æ¶æ„å±‚æ¬¡ï¼šService -> Store -> Database
// è®¾è®¡è¦ç‚¹ï¼š
// - æ¯æ—¥å‡Œæ™¨01:00æ‰§è¡Œ
// - èšåˆå‰ä¸€å¤©çš„æ•°æ®
// - æ”¯æŒé‡å¤æ‰§è¡Œï¼ˆä½¿ç”¨ ON DUPLICATE KEY UPDATEï¼‰
// - åˆ†åˆ«èšåˆï¼šä»»åŠ¡ç»Ÿè®¡ã€CronJobç»Ÿè®¡ã€Workerç»Ÿè®¡
type StatsAggregator struct {
	aggregatorStore store.StatsAggregatorStore
}

// NewStatsAggregator åˆ›å»ºç»Ÿè®¡èšåˆå™¨å®ä¾‹
func NewStatsAggregator(aggregatorStore store.StatsAggregatorStore) *StatsAggregator {
	return &StatsAggregator{
		aggregatorStore: aggregatorStore,
	}
}

// AggregateDailyStats èšåˆæ¯æ—¥ç»Ÿè®¡æ•°æ®
//
// ä¸»å…¥å£å‡½æ•°ï¼Œèšåˆå‰ä¸€å¤©çš„æ‰€æœ‰ç»Ÿè®¡æ•°æ®
// å‚æ•°:
//   - targetDate: ç›®æ ‡æ—¥æœŸï¼ˆæ ¼å¼ï¼š2006-01-02ï¼‰ï¼Œå¦‚æœä¸ºç©ºåˆ™é»˜è®¤ä¸ºæ˜¨å¤©
//
// è¿”å›å€¼:
//   - error: å¦‚æœèšåˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
func (a *StatsAggregator) AggregateDailyStats(targetDate string) error {
	// å¦‚æœæœªæŒ‡å®šæ—¥æœŸï¼Œé»˜è®¤èšåˆæ˜¨å¤©çš„æ•°æ®
	if targetDate == "" {
		yesterday := time.Now().AddDate(0, 0, -1)
		targetDate = yesterday.Format("2006-01-02")
	}

	logger.Info("å¼€å§‹èšåˆæ¯æ—¥ç»Ÿè®¡æ•°æ®",
		zap.String("target_date", targetDate))

	startTime := time.Now()

	// ğŸ”¥ 1. èšåˆä»»åŠ¡ç»Ÿè®¡
	if err := a.aggregateTaskStats(targetDate); err != nil {
		logger.Error("èšåˆä»»åŠ¡ç»Ÿè®¡å¤±è´¥",
			zap.String("target_date", targetDate),
			zap.Error(err))
		return fmt.Errorf("èšåˆä»»åŠ¡ç»Ÿè®¡å¤±è´¥: %w", err)
	}

	// ğŸ”¥ 2. èšåˆCronJobç»Ÿè®¡
	if err := a.aggregateCronjobStats(targetDate); err != nil {
		logger.Error("èšåˆCronJobç»Ÿè®¡å¤±è´¥",
			zap.String("target_date", targetDate),
			zap.Error(err))
		return fmt.Errorf("èšåˆCronJobç»Ÿè®¡å¤±è´¥: %w", err)
	}

	// ğŸ”¥ 3. èšåˆWorkerç»Ÿè®¡
	if err := a.aggregateWorkerStats(targetDate); err != nil {
		logger.Error("èšåˆWorkerç»Ÿè®¡å¤±è´¥",
			zap.String("target_date", targetDate),
			zap.Error(err))
		return fmt.Errorf("èšåˆWorkerç»Ÿè®¡å¤±è´¥: %w", err)
	}

	duration := time.Since(startTime)
	logger.Info("æ¯æ—¥ç»Ÿè®¡æ•°æ®èšåˆå®Œæˆ",
		zap.String("target_date", targetDate),
		zap.Duration("duration", duration))

	return nil
}

// aggregateTaskStats èšåˆä»»åŠ¡ç»Ÿè®¡æ•°æ®ï¼ˆè°ƒç”¨ Store å±‚ï¼‰
func (a *StatsAggregator) aggregateTaskStats(targetDate string) error {
	logger.Info("å¼€å§‹èšåˆä»»åŠ¡ç»Ÿè®¡", zap.String("date", targetDate))

	// è°ƒç”¨ Store å±‚æ‰§è¡Œèšåˆ
	affectedRows, skippedNullTeam, err := a.aggregatorStore.AggregateTaskStats(targetDate)
	if err != nil {
		return err
	}

	logger.Info("ä»»åŠ¡ç»Ÿè®¡èšåˆå®Œæˆ",
		zap.String("date", targetDate),
		zap.Int64("affected_rows", affectedRows),
		zap.Int64("skipped_null_team", skippedNullTeam))

	return nil
}

// aggregateCronjobStats èšåˆCronJobç»Ÿè®¡æ•°æ®ï¼ˆè°ƒç”¨ Store å±‚ï¼‰
func (a *StatsAggregator) aggregateCronjobStats(targetDate string) error {
	logger.Info("å¼€å§‹èšåˆCronJobç»Ÿè®¡", zap.String("date", targetDate))

	// è°ƒç”¨ Store å±‚æ‰§è¡Œèšåˆ
	affectedRows, err := a.aggregatorStore.AggregateCronjobStats(targetDate)
	if err != nil {
		return err
	}

	logger.Info("CronJobç»Ÿè®¡èšåˆå®Œæˆ",
		zap.String("date", targetDate),
		zap.Int64("affected_rows", affectedRows))

	return nil
}

// aggregateWorkerStats èšåˆWorkerç»Ÿè®¡æ•°æ®ï¼ˆè°ƒç”¨ Store å±‚ï¼‰
func (a *StatsAggregator) aggregateWorkerStats(targetDate string) error {
	logger.Info("å¼€å§‹èšåˆWorkerç»Ÿè®¡", zap.String("date", targetDate))

	// è°ƒç”¨ Store å±‚æ‰§è¡Œèšåˆ
	affectedRows, err := a.aggregatorStore.AggregateWorkerStats(targetDate)
	if err != nil {
		return err
	}

	logger.Info("Workerç»Ÿè®¡èšåˆå®Œæˆ",
		zap.String("date", targetDate),
		zap.Int64("affected_rows", affectedRows))

	return nil
}

// AggregateHistoricalStats èšåˆå†å²ç»Ÿè®¡æ•°æ®
//
// ç”¨äºé¦–æ¬¡éƒ¨ç½²æˆ–è¡¥å……å†å²æ•°æ®
// å‚æ•°:
//   - startDate: å¼€å§‹æ—¥æœŸï¼ˆæ ¼å¼ï¼š2006-01-02ï¼‰
//   - endDate: ç»“æŸæ—¥æœŸï¼ˆæ ¼å¼ï¼š2006-01-02ï¼‰
//
// è¿”å›å€¼:
//   - error: å¦‚æœèšåˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
func (a *StatsAggregator) AggregateHistoricalStats(startDate, endDate string) error {
	logger.Info("å¼€å§‹èšåˆå†å²ç»Ÿè®¡æ•°æ®",
		zap.String("start_date", startDate),
		zap.String("end_date", endDate))

	start, err := time.Parse("2006-01-02", startDate)
	if err != nil {
		return fmt.Errorf("å¼€å§‹æ—¥æœŸæ ¼å¼é”™è¯¯: %w", err)
	}

	end, err := time.Parse("2006-01-02", endDate)
	if err != nil {
		return fmt.Errorf("ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯: %w", err)
	}

	// é€å¤©èšåˆ
	successCount := 0
	failCount := 0

	for d := start; !d.After(end); d = d.AddDate(0, 0, 1) {
		dateStr := d.Format("2006-01-02")

		if err := a.AggregateDailyStats(dateStr); err != nil {
			logger.Error("èšåˆå¤±è´¥",
				zap.String("date", dateStr),
				zap.Error(err))
			failCount++
			// ç»§ç»­å¤„ç†ä¸‹ä¸€å¤©ï¼Œä¸ä¸­æ–­
		} else {
			successCount++
		}
	}

	logger.Info("å†å²ç»Ÿè®¡æ•°æ®èšåˆå®Œæˆ",
		zap.String("start_date", startDate),
		zap.String("end_date", endDate),
		zap.Int("success_count", successCount),
		zap.Int("fail_count", failCount))

	if failCount > 0 {
		return fmt.Errorf("éƒ¨åˆ†æ—¥æœŸèšåˆå¤±è´¥: %d/%d", failCount, successCount+failCount)
	}

	return nil
}
